{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from si.data.dataset import Dataset\n",
    "from si.io.csv_file import read_csv\n",
    "from si.feature_selection.select_percentile import SelectPercentile\n",
    "from si.statistics.f_classification import f_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Class 1\n",
    "#### Exercise 1: NumPy array Indexing/Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EXERCICIO 1\n",
    "\n",
    "#1.1 - Loading the \"iris.csv\" using the appropriate method\n",
    "\n",
    "path = r'C:\\Users\\joana\\OneDrive\\Documentos\\GitHub\\si\\datasets\\iris\\iris.csv'\n",
    "\n",
    "dataset = read_csv(path,features=True, label=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penultimate Independent Variable:\n",
      "[1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n",
      " 1.7 1.5 1.7 1.5 1.  1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n",
      " 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.\n",
      " 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.  4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.\n",
      " 4.9 4.7 4.3 4.4 4.8 5.  4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.\n",
      " 4.4 4.6 4.  3.3 4.2 4.2 4.2 4.3 3.  4.1 6.  5.1 5.9 5.6 5.8 6.6 4.5 6.3\n",
      " 5.8 6.1 5.1 5.3 5.5 5.  5.1 5.3 5.5 6.7 6.9 5.  5.7 4.9 6.7 4.9 5.7 6.\n",
      " 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n",
      " 5.7 5.2 5.  5.2 5.4 5.1]\n",
      "Dimension of the Resulting Array:\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# 1.2) Select the penultimate independent variable\n",
    "\n",
    "penultima_feature = dataset.X[:, -2]\n",
    "dimensao = penultima_feature.shape\n",
    "\n",
    "print(\"Penultimate Independent Variable:\")\n",
    "print(penultima_feature)\n",
    "print(\"Dimension of the Resulting Array:\")\n",
    "print(dimensao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 10 Samples:\n",
      "[[6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "Mean for Each Independent Variable/Feature:\n",
      "[6.45 3.03 5.33 2.17]\n"
     ]
    }
   ],
   "source": [
    "#1.3 Select the last 10 samples and calculate the mean for each feature\n",
    "\n",
    "last_10_samples = dataset.X[-10:]\n",
    "mean = last_10_samples.mean(axis=0)\n",
    "\n",
    "print(\"Last 10 Samples:\")\n",
    "print(last_10_samples)\n",
    "print(\"Mean for Each Independent Variable/Feature:\")\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples with Values less than or equal to 6 for All Independent Variables:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "Number of Samples: 89\n"
     ]
    }
   ],
   "source": [
    "#1.4 Select samples with values less than or equal to 6 for all independent variables\n",
    "\n",
    "selected_samples = dataset.X[(dataset.X <= 6).all(axis=1)]\n",
    "print(\"Samples with Values less than or equal to 6 for All Independent Variables:\")\n",
    "print(selected_samples)\n",
    "num_selected_samples = len(selected_samples)\n",
    "print(\"Number of Samples:\", num_selected_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples with a Different Class/Label from 'Iris-setosa':\n",
      "[[7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "Number of Samples: 100\n"
     ]
    }
   ],
   "source": [
    "# 1.5) Select samples with a class/label different from 'Irissetosa'\n",
    "\n",
    "different_class_samples = dataset.X[dataset.y != 'Iris-setosa']\n",
    "print(\"Samples with a Different Class/Label from 'Iris-setosa':\")\n",
    "print(different_class_samples)\n",
    "num_different_class_samples = len(different_class_samples)\n",
    "print(\"Number of Samples:\", num_different_class_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: You can add examples of how to use these methods to the script/notebook of Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropna:\n",
      "Dataset shape: (150, 4)\n",
      "\n",
      "After dropna:\n",
      "Dataset shape: (150, 4)\n",
      "\n",
      "Before fillna with 0:\n",
      "        sepal_length  sepal_width  petal_length  petal_width\n",
      "mean        5.843333     3.054000      3.758667     1.198667\n",
      "median      5.800000     3.000000      4.350000     1.300000\n",
      "min         4.300000     2.000000      1.000000     0.100000\n",
      "max         7.900000     4.400000      6.900000     2.500000\n",
      "var         0.681122     0.186751      3.092425     0.578532\n",
      "\n",
      "Filling NaNs with 0:\n",
      "\n",
      "After fillna with 0:\n",
      "        sepal_length  sepal_width  petal_length  petal_width\n",
      "mean        5.843333     3.054000      3.758667     1.198667\n",
      "median      5.800000     3.000000      4.350000     1.300000\n",
      "min         4.300000     2.000000      1.000000     0.100000\n",
      "max         7.900000     4.400000      6.900000     2.500000\n",
      "var         0.681122     0.186751      3.092425     0.578532\n",
      "\n",
      "Before removing sample by index:\n",
      "Dataset shape: (150, 4)\n",
      "\n",
      "After removing sample at index 3:\n",
      "Dataset shape: (149, 4)\n"
     ]
    }
   ],
   "source": [
    "from si.data.dataset import Dataset\n",
    "\n",
    "\n",
    "print(\"Before dropna:\")\n",
    "print(\"Dataset shape:\", dataset.shape())\n",
    "dataset.dropna()\n",
    "print(\"\\nAfter dropna:\")\n",
    "print(\"Dataset shape:\", dataset.shape())\n",
    "\n",
    "print(\"\\nBefore fillna with 0:\")\n",
    "print(dataset.summary())\n",
    "print(\"\\nFilling NaNs with 0:\")\n",
    "dataset.fillna(0)\n",
    "print(\"\\nAfter fillna with 0:\")\n",
    "print(dataset.summary())\n",
    "\n",
    "print(\"\\nBefore removing sample by index:\")\n",
    "print(\"Dataset shape:\", dataset.shape())\n",
    "dataset.remove_by_index(3)\n",
    "print(\"\\nAfter removing sample at index 3:\")\n",
    "print(\"Dataset shape:\", dataset.shape())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 2\n",
    "#### Exercise 3: Implementing SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"\\\\Users\\\\joana\\\\OneDrive\\\\Documentos\\\\GitHub\\\\si\\\\datasets\\\\iris\\\\iris.csv\"\n",
    "dataset = read_csv(filename= filename, sep = ',', features = True, label = True)\n",
    "dataset.X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features with percentile 0:  4\n",
      "Number of features with percentile 25:  1\n",
      "Number of features with percentile 50:  2\n",
      "Number of features with percentile 75:  3\n",
      "Number of features with percentile 100:  4\n"
     ]
    }
   ],
   "source": [
    "selector0 = SelectPercentile(f_classification, percentile = 0)\n",
    "selector25 = SelectPercentile(f_classification, percentile = 0.25)\n",
    "selector50 = SelectPercentile(f_classification, percentile = 0.50)\n",
    "selector75 = SelectPercentile(f_classification, percentile = 0.75)\n",
    "selector1 = SelectPercentile(f_classification, percentile = 1)\n",
    "\n",
    "\n",
    "# do the fit_transform to all selectors and show the len of the features\n",
    "transform0 = selector0.fit_transform(dataset)\n",
    "print(\"Number of features with percentile 0: \", len(transform0.features))\n",
    "\n",
    "\n",
    "transform25 = selector25.fit_transform(dataset)\n",
    "print(\"Number of features with percentile 25: \", len(transform25.features))\n",
    "\n",
    "\n",
    "transform50 = selector50.fit_transform(dataset)\n",
    "print(\"Number of features with percentile 50: \", len(transform50.features))\n",
    "\n",
    "transform75 = selector75.fit_transform(dataset)\n",
    "print(\"Number of features with percentile 75: \", len(transform75.features))\n",
    "\n",
    "transform1 = selector1.fit_transform(dataset)\n",
    "print(\"Number of features with percentile 100: \", len(transform1.features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Exercise 4: Test Manhattan distance \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan funtion = [0 9]\n",
      "sklearn funtion = [[0. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import manhattan_distances as manhattan_distances_sklearn\n",
    "from si.statistics.manhattan_distance import manhattan_distance\n",
    "\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "distance = manhattan_distance(x, y)\n",
    "\n",
    "# sklearn distance\n",
    "\n",
    "sklearn_distance = manhattan_distances_sklearn(x.reshape(1, -1), y)\n",
    "assert np.allclose(distance, sklearn_distance)\n",
    "\n",
    "print(f\"Manhattan funtion = {distance}\")\n",
    "print(f\"sklearn funtion = {sklearn_distance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Test the PCA Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36158968 -0.08226889  0.85657211  0.35884393]\n",
      " [-0.65653988 -0.72971237  0.1757674   0.07470647]]\n",
      "[[ 0.36158968 -0.08226889  0.85657211  0.35884393]\n",
      " [ 0.65653988  0.72971237 -0.1757674  -0.07470647]]\n"
     ]
    }
   ],
   "source": [
    "# test PCA function\n",
    "\n",
    "from si.decomposition.pca import PCA\n",
    "from sklearn.decomposition import PCA as PCA_sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load dataset\n",
    "filename = \"\\\\Users\\\\joana\\\\OneDrive\\\\Documentos\\\\GitHub\\\\si\\\\datasets\\\\iris\\\\iris.csv\"\n",
    "dataset = read_csv(filename= filename, sep = ',', features = True, label = True)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit_transform(dataset)\n",
    "\n",
    "print(pca.components)\n",
    "\n",
    "# sklearn PCA\n",
    "pca_sklearn = PCA_sklearn(n_components=2)\n",
    "pca_sklearn.fit_transform(dataset.X)\n",
    "print(pca_sklearn.components_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Exercise 6: Implementing stratified splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stratified split:\n",
      "Train dataset shape: (120, 4)\n",
      "Test dataset shape: (30, 4)\n",
      "\n",
      "\n",
      "\n",
      "After stratified split:\n",
      "Train dataset shape: (30, 4)\n",
      "Test dataset shape: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from si.data.dataset import Dataset\n",
    "from si.model_selection.split import stratified_train_test_split\n",
    "from si.model_selection.split import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "filename = \"\\\\Users\\\\joana\\\\OneDrive\\\\Documentos\\\\GitHub\\\\si\\\\datasets\\\\iris\\\\iris.csv\"\n",
    "dataset = read_csv(filename= filename, sep = ',', features = True, label = True)\n",
    "\n",
    "print(\"Before stratified split:\")\n",
    "\n",
    "train1, test1 = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "print(\"Train dataset shape:\", train1.shape())\n",
    "print(\"Test dataset shape:\", test1.shape())\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"After stratified split:\")\n",
    "\n",
    "train, test = stratified_train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "print(\"Train dataset shape:\", train.shape())\n",
    "print(\"Test dataset shape:\", test.shape())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Implementing the KNNRegressor with RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 3.0\n",
      "RMSE sklearn = 3.0\n"
     ]
    }
   ],
   "source": [
    "### RMSE\n",
    "\n",
    "# test RMSE function\n",
    "\n",
    "from si.metrics.rmse import rmse\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array([1, 2, 3])\n",
    "y_pred = np.array([4, 5, 6])\n",
    "rmse_value = rmse(y_true, y_pred)\n",
    "\n",
    "print(f\"RMSE = {rmse_value}\")\n",
    "\n",
    "# compare with sklearn RMSE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_sklearn = sqrt(mean_squared_error(y_true, y_pred))\n",
    "assert np.allclose(rmse_value, rmse_sklearn)\n",
    "\n",
    "print(f\"RMSE sklearn = {rmse_sklearn}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score RMSE: 81.36259969252635\n"
     ]
    }
   ],
   "source": [
    "### KNN\n",
    "\n",
    "from si.model_selection.split import train_test_split\n",
    "from si.models.knn_regressor import KNNRegressor\n",
    "\n",
    "cpu = read_csv(\"\\\\Users\\\\joana\\\\OneDrive\\\\Documentos\\\\GitHub\\\\si\\\\datasets\\\\cpu\\\\cpu.csv\", sep = \",\", features=True, label=True)\n",
    "\n",
    "train, test = train_test_split(cpu, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize the KNN_Classifier\n",
    "\n",
    "knn = KNNRegressor(k=3)\n",
    "\n",
    "# fit the model\n",
    "\n",
    "knn.fit(train)\n",
    "\n",
    "# evaluate the model on test data\n",
    "\n",
    "score = knn.score(test)\n",
    "print(\"Score RMSE:\", score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score RMSE sklearn: 81.36021813423898\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### KNN sklearn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "knn_sklearn = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_sklearn.fit(train.X, train.y)\n",
    "y_pred = knn_sklearn.predict(test.X)\n",
    "score_sklearn = sqrt(mean_squared_error(test.y, y_pred))\n",
    "\n",
    "print(\"Score RMSE sklearn:\", score_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional – Categorical Naïve-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [0 1 0 1]\n",
      "Classification error: 0.0\n",
      "Predicted classes: [0 1 0 1]\n",
      "Classification error: 0.0\n"
     ]
    }
   ],
   "source": [
    "### test categoricalnaivebayes\n",
    "\n",
    "from si.models.categorical_nb import CategoricalNB\n",
    "from si.data.dataset import Dataset\n",
    "\n",
    "\n",
    "X = np.array([[0, 1, 0], [1, 0, 1], [1, 1, 0], [0, 1, 1]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "  \n",
    "dataset = Dataset(X, y)\n",
    "\n",
    "model = CategoricalNB(smoothing=1)\n",
    "model.fit(dataset)\n",
    "\n",
    "predictions = model.predict(dataset)\n",
    "error = model.score(dataset)\n",
    "\n",
    "print(\"Predicted classes:\", predictions)\n",
    "print(\"Classification error:\", error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes sklearn: [0 1 0 1]\n",
      "Classification error sklearn: 1.0\n"
     ]
    }
   ],
   "source": [
    "# test categoricalnaivebayes sklearn with the same dataset\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB as CategoricalNB_sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_sklearn = CategoricalNB_sklearn(alpha=1)\n",
    "model_sklearn.fit(X, y)\n",
    "predictions_sklearn = model_sklearn.predict(X)\n",
    "error_sklearn = accuracy_score(y, predictions_sklearn)\n",
    "\n",
    "print(\"Predicted classes sklearn:\", predictions_sklearn)\n",
    "print(\"Classification error sklearn:\", error_sklearn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 5\n",
    "             \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8: Test RidgeRegression with Least Squares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58823529 1.08145743]\n",
      "8.5\n",
      "0.07698961937716277\n"
     ]
    }
   ],
   "source": [
    "# test ridge regression with least squares function\n",
    "\n",
    "from si.models.ridge_regression_least_squares import RidgeRegressionLeastSquares\n",
    "from si.data.dataset import Dataset\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "dataset_ = Dataset(X=X, y=y)\n",
    "\n",
    "# fit the model\n",
    "model = RidgeRegressionLeastSquares()\n",
    "model.fit(dataset_)\n",
    "print(model.theta)\n",
    "print(model.theta_zero)\n",
    "\n",
    "# compute the score\n",
    "print(model.score(dataset_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58823529 1.08145743]\n",
      "8.5\n",
      "0.07698961937716259\n"
     ]
    }
   ],
   "source": [
    "### test ridge regression with least squares\n",
    "\n",
    "from si.models.ridge_regression import RidgeRegression\n",
    "from si.data.dataset import Dataset\n",
    "import numpy as np\n",
    "from si.io.csv_file import read_csv\n",
    "from si.metrics.mse import mse\n",
    "from si.model_selection.split import *\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge()\n",
    "    # scale data\n",
    "X = (dataset_.X - np.nanmean(dataset_.X, axis=0)) / np.nanstd(dataset_.X, axis=0)\n",
    "model.fit(X, dataset_.y)\n",
    "print(model.coef_) # should be the same as theta\n",
    "print(model.intercept_) # should be the same as theta_zero\n",
    "print(mse(dataset_.y, model.predict(X)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9: Test the RandomForestClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Literal' from 'typing' (c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28576\\160087325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### test random forest classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_forest_classifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\joana_oliveira_gon_alves-0.0.1-py3.7.egg\\si\\models\\random_forest_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_tree_classifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\joana_oliveira_gon_alves-0.0.1-py3.7.egg\\si\\models\\decision_tree_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Literal' from 'typing' (c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\typing.py)"
     ]
    }
   ],
   "source": [
    "### test random forest classifier\n",
    "\n",
    "from si.models.random_forest_classifier import RandomForestClassifier\n",
    "from si.data.dataset import Dataset\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "dataset_ = Dataset(X=X, y=y)\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "\n",
    "model.fit(dataset_)\n",
    "\n",
    "# compute the score\n",
    "\n",
    "print(model.score(dataset_))\n",
    "\n",
    "# test random forest classifier sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForestClassifier_sklearn\n",
    "\n",
    "model_sklearn = RandomForestClassifier_sklearn(n_estimators=100, max_depth=2)\n",
    "\n",
    "model_sklearn.fit(X, y)\n",
    "\n",
    "print(model_sklearn.score(X, y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 10: Implementing the StackingClassifier ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Literal' from 'typing' (c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28576\\3945537016.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknn_classifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNNClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogistic_regression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_tree_classifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstacking_classifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\joana_oliveira_gon_alves-0.0.1-py3.7.egg\\si\\models\\decision_tree_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Literal' from 'typing' (c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\typing.py)"
     ]
    }
   ],
   "source": [
    "# test stacking classifier\n",
    "\n",
    "\n",
    "\n",
    "from si.io.csv_file import read_csv\n",
    "from si.model_selection.split import stratified_train_test_split\n",
    "from si.models.knn_classifier import KNNClassifier\n",
    "from si.models.logistic_regression import LogisticRegression\n",
    "from si.models.decision_tree_classifier import DecisionTreeClassifier\n",
    "from si.metrics.accuracy import accuracy\n",
    "from si.ensemble.stacking_classifier import StackingClassifier\n",
    "\n",
    "data = read_csv('C:\\\\Users\\\\joana\\\\OneDrive\\\\Documentos\\\\GitHub\\\\si\\\\datasets\\\\breast_bin\\\\breast-bin.csv', sep=\",\",features=True,label=True)\n",
    "train, test = stratified_train_test_split(data, test_size=0.20, random_state=42)\n",
    "\n",
    "#knnregressor\n",
    "knn = KNNClassifier(k=5)\n",
    "    \n",
    "#logistic regression\n",
    "lr=LogisticRegression(l2_penalty=0.1, alpha=0.1, max_iter=1000)\n",
    "\n",
    "#decisiontreee\n",
    "dt=DecisionTreeClassifier(min_sample_split=2, max_depth=10, mode='gini')\n",
    "\n",
    "#final model\n",
    "final_model=KNNClassifier(k=5)\n",
    "modelos=[knn,lr,dt]\n",
    "exercise=StackingClassifier(modelos,final_model)\n",
    "exercise.fit(train)\n",
    "print(exercise.score(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (87) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (89) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (87) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (91) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (85) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (87) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (89) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (87) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (91) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (85) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (87) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (89) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (87) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (91) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "c:\\Users\\joana\\anaconda3\\envs\\si\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1097: RuntimeWarning: Number of classes in training fold (85) does not match total number of classes (101). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28576\\1489178158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mexercise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStackingClassifier_sklearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mexercise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexercise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# test stacking classifier sklearn\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier as StackingClassifier_sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#knnregressor\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#logistic regression\n",
    "lr=LogisticRegression(penalty='l2', C=0.1, max_iter=1000)\n",
    "\n",
    "#decisiontreee\n",
    "dt=DecisionTreeClassifier(min_samples_split=2, max_depth=10, criterion='gini')\n",
    "\n",
    "#final model\n",
    "final_model=KNeighborsClassifier(n_neighbors=5)\n",
    "models=[('knn',knn),('lr',lr),('dt',dt)]\n",
    "exercise=StackingClassifier_sklearn(estimators=models,final_estimator=final_model)\n",
    "exercise.fit(train.X, train.y)\n",
    "print(accuracy(test.y, exercise.predict(test.X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 11: Test the randomized_search_cv function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
